{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as func\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_weights():\n",
    "    idx = 0\n",
    "    words_dict = {}\n",
    "    vectors = []\n",
    "    with open(\"glove6b/glove.6B/glove.6B.300d.txt\", 'r') as file:\n",
    "        for row in file:\n",
    "            word, *weights = row.split()\n",
    "            weights = list(map(float, weights))\n",
    "            words_dict[word] = idx\n",
    "            idx +=1\n",
    "            vectors.append(weights)\n",
    "    return words_dict, vectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM_SIZE=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_dict, vectors = create_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"labeledTrainData.tsv\", sep='\\t')\n",
    "data_predict = pd.read_csv(\"testData.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(text):\n",
    "    text = re.sub(\"<[^>]*>\", \"\",text)\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    words = text.split()\n",
    "    words = [word.lower() for word in words]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_words_unique(reviews):\n",
    "    all_words = set()\n",
    "    for text in data.review:\n",
    "        words = get_words(text)\n",
    "        all_words.update(set(words))\n",
    "    all_words = list(all_words)\n",
    "    return all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = get_all_words_unique(pd.concat([data.review, data_predict.review]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_weights_matrix(all_words, vectors, words_dict):\n",
    "    weights_len = len(all_words)+1\n",
    "    weights_matrix = np.zeros((weights_len, DIM_SIZE))\n",
    "    word_idx = {}\n",
    "    for i, word in enumerate(all_words):\n",
    "        if word in words_dict:\n",
    "            weights_matrix[i] = np.array(vectors[words_dict[word]])\n",
    "        else:\n",
    "            weights_matrix[i] = np.random.normal(0,1,DIM_SIZE)\n",
    "        word_idx[word] = i\n",
    "    padding_index = len(all_words)\n",
    "    weights_matrix[padding_index] = np.zeros(DIM_SIZE)\n",
    "    return weights_matrix, word_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_matrix, word_idx = create_weights_matrix(all_words, vectors, words_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conver_review_to_idx(text):\n",
    "    return [word_idx[word] for word in get_words(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = list(data.review)\n",
    "reviews = [conver_review_to_idx(review) for review in reviews]\n",
    "sentiments = list(data.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287\n"
     ]
    }
   ],
   "source": [
    "review_lengths = [len(review) for review in reviews]\n",
    "pad_value = int(np.percentile(review_lengths, 75))\n",
    "print(pad_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sentences(x, size):\n",
    "    new_x = np.zeros((len(x), size))\n",
    "    for i in range(len(x)):\n",
    "        if len(x[i])>=size:\n",
    "            new_x[i] = x[i][:size]\n",
    "        else:\n",
    "            new_x[i] = x[i]+[0]*(size-len(x[i]))\n",
    "    return new_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pad_sentences(reviews, pad_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emb_layer(emb_matrix):\n",
    "    emb_size, dim_size = emb_matrix.shape\n",
    "    layer = torch.nn.Embedding(emb_size, dim_size, padding_idx=0)\n",
    "    layer.load_state_dict({'weight':torch.Tensor(emb_matrix)})\n",
    "    return layer, emb_size, dim_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierCNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.emb_layer, emb_size, dim_size = create_emb_layer(emb_matrix)\n",
    "        self.conv_3 = torch.nn.Conv2d(in_channels=1, out_channels=100, kernel_size=[3, dim_size])\n",
    "        self.conv_4 = torch.nn.Conv2d(in_channels=1, out_channels=100, kernel_size=[4, dim_size])\n",
    "        self.conv_5 = torch.nn.Conv2d(in_channels=1, out_channels=100, kernel_size=[5, dim_size])\n",
    "        \n",
    "        self.percp = torch.nn.Linear(3*100, 1)\n",
    "        self.dropout = torch.nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, text):\n",
    "        text = torch.tensor(list(np.transpose(text)), dtype=torch.long)\n",
    "        text = self.emb_layer(text).permute(1,0,2)\n",
    "        #print(text.size())\n",
    "        \n",
    "        text = text.unsqueeze(1)\n",
    "        #print(text.size())\n",
    "        \n",
    "        conved3 = self.conv_3(text).squeeze(3)\n",
    "        conved4 = self.conv_4(text).squeeze(3)\n",
    "        conved5 = self.conv_5(text).squeeze(3)\n",
    "        #print (conved3.size())\n",
    "        \n",
    "        relu3 = torch.nn.functional.relu(conved3)\n",
    "        relu4 = torch.nn.functional.relu(conved4)\n",
    "        relu5 = torch.nn.functional.relu(conved5)\n",
    "        #print(relu3.size())\n",
    "        \n",
    "        pooled3 = torch.nn.functional.max_pool1d(relu3, relu3.shape[2]).squeeze(2)\n",
    "        pooled4 = torch.nn.functional.max_pool1d(relu4, relu4.shape[2]).squeeze(2)\n",
    "        pooled5 = torch.nn.functional.max_pool1d(relu5, relu5.shape[2]).squeeze(2)\n",
    "        #print(pooled3.size())\n",
    "        \n",
    "        cat = torch.cat((pooled3, pooled4, pooled5), dim=1)\n",
    "        cat_dropout = self.dropout(cat)\n",
    "        return self.percp(cat_dropout)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_train, reviews_val, labels_train, labels_val = train_test_split(reviews, sentiments, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ClassifierCNN()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, texts, labels):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    batch_size=50\n",
    "    texts_amount = len(texts)\n",
    "    iteration_amount = math.ceil(texts_amount/batch_size)\n",
    "    \n",
    "    for i in range(iteration_amount):\n",
    "        x = texts[(i*batch_size):min(texts_amount, (i+1)*batch_size)]\n",
    "        #print(x)\n",
    "        y = torch.tensor(labels[(i*batch_size):min(texts_amount, (i+1)*batch_size)], dtype=torch.float32)\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(x)\n",
    "        #print(predictions)\n",
    "        predictions = predictions.squeeze(1)\n",
    "        #print (predictions.type())\n",
    "        loss = criterion(predictions, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_m(model, texts, sentiments):\n",
    "    model.eval()\n",
    "    batch_size=50\n",
    "    texts_amount = len(texts)\n",
    "    iteration_amount = math.ceil(texts_amount/batch_size)\n",
    "    \n",
    "    predictions_all = np.array([])\n",
    "    for i in range(iteration_amount):\n",
    "        x = texts[(i*batch_size):min(texts_amount, (i+1)*batch_size)]\n",
    "        predictions = model(x)\n",
    "        res = torch.sigmoid(predictions).detach().numpy()\n",
    "        predictions_all = np.append(predictions_all, res)\n",
    "    \n",
    "    predictions_all = np.array([1 if x >= 0.5 else 0 for x in predictions_all])\n",
    "    accuracy = sum(predictions_all==np.array(sentiments))/len(predictions_all)\n",
    "    return predictions_all, accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_m_witout_testing(model, texts):\n",
    "    model.eval()\n",
    "    batch_size=50\n",
    "    texts_amount = len(texts)\n",
    "    iteration_amount = math.ceil(texts_amount/batch_size)\n",
    "    \n",
    "    predictions_all = np.array([])\n",
    "    for i in range(iteration_amount):\n",
    "        x = texts[(i*batch_size):min(texts_amount, (i+1)*batch_size)]\n",
    "        predictions = model(x)\n",
    "        res = torch.sigmoid(predictions).detach().numpy()\n",
    "        predictions_all = np.append(predictions_all, res)\n",
    "    \n",
    "    predictions_all = np.array([1 if x >= 0.5 else 0 for x in predictions_all])\n",
    "    return predictions_all\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(1, 4):\n",
    "    print(i)\n",
    "    train(model, optimizer, criterion, reviews, sentiments)\n",
    "    #pred_all, accuracy = eval_m(model, reviews_val, labels_val)\n",
    "    #print (\"%d - %f\" % (i, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - 0.840000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 1, 0, ..., 0, 0, 1]), 0.98796)"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 3, 4])"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.append(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3])"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_to_predict = list(data_to_predict.review)\n",
    "reviews_to_predict = [preprocess(review) for review in reviews_to_predict]\n",
    "reviews_to_predict = pad_sentences(reviews_to_predict, 282)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = eval_m_witout_testing(model, reviews_to_predict)\n",
    "pred_all = [1 if x >= 0.5 else 0 for x in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_predict['sentiment'] = pred_all\n",
    "data_to_predict[['id','sentiment']].to_csv(\"cnn6.csv\",index=False, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews_to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
